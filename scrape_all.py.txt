import requests
import json
import os
import time
from bs4 import BeautifulSoup
from datetime import datetime

HEADERS = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'}

os.makedirs("data", exist_ok=True)

def scrape_krypdrops():
    """Krypdrops - Active airdrops (TG MiniApp, DePIN)"""
    url = "https://krypdrops.com/airdrops/"
    try:
        r = requests.get(url, headers=HEADERS, timeout=15)
        soup = BeautifulSoup(r.text, 'html.parser')
        # Flexible selector based on test (table or list items)
        items = soup.select('tr, .airdrop-item, article')[:10]
        data = []
        for i in items:
            title = i.select_one('td:first-child, h3, .title').text.strip() if i.select_one('td:first-child, h3, .title') else "Unknown"
            desc = i.select_one('.desc, td:nth-child(2)').text.strip() if i.select_one('.desc, td:nth-child(2)') else ""
            reward = i.select_one('.reward, td:nth-child(3)').text.strip() if i.select_one('.reward, td:nth-child(3)') else "Free"
            end = i.select_one('.end, td:last-child').text.strip() if i.select_one('.end, td:last-child') else "Q2 2025"
            link = i.select_one('a')['href'] if i.select_one('a') else url
            if not link.startswith('http'): link = "https://krypdrops.com" + link
            # Filter active (exclude Ended)
            if "ended" not in end.lower():
                data.append({"source": "krypdrops.com", "title": title, "description": desc, "reward": reward, "end": end, "link": link})
        return data
    except Exception as e:
        print(f"krypdrops error: {e}")
        return []

def scrape_airdropsmob():
    """AirdropsMob - Easy Telegram/Twitter airdrops"""
    url = "https://www.airdropsmob.com/"
    try:
        r = requests.get(url, headers=HEADERS, timeout=15)
        soup = BeautifulSoup(r.text, 'html.parser')
        items = soup.select('.airdrop-card, article, .item')[:10]
        data = []
        for i in items:
            title = i.select_one('h3, .title').text.strip() if i.select_one('h3, .title') else "Unknown"
            desc = i.select_one('.desc, .requirements').text.strip() if i.select_one('.desc, .requirements') else ""
            reward = i.select_one('.reward, .token').text.strip() if i.select_one('.reward, .token') else "TBA"
            end = i.select_one('.end, .status').text.strip() if i.select_one('.end, .status') else "Ongoing"
            link = i.select_one('a')['href'] if i.select_one('a') else url
            if not link.startswith('http'): link = "https://www.airdropsmob.com" + link
            # Filter active
            if "expire" not in end.lower() or "ongoing" in end.lower():
                data.append({"source": "airdropsmob.com", "title": title, "description": desc, "reward": reward, "end": end, "link": link})
        return data
    except Exception as e:
        print(f"airdropsmob error: {e}")
        return []

def scrape_airdrops():
    """Multi-source: Prioritas link user (krypdrops + airdropsmob + fallback)"""
    data = scrape_krypdrops() + scrape_airdropsmob()
    # Tambah fallback dari airdrops.io jika perlu (dari test sebelumnya)
    try:
        r = requests.get("https://airdrops.io/latest/", headers=HEADERS, timeout=15)
        soup = BeautifulSoup(r.text, 'html.parser')
        items = soup.select('.airdrop-item')[:5]
        for i in items:
            title = i.select_one('.airdrop-title a').text.strip() if i.select_one('.airdrop-title a') else "Unknown"
            link = "https://airdrops.io" + i.select_one('.airdrop-title a')['href'] if i.select_one('.airdrop-title a') else ""
            reward = i.select_one('.airdrop-reward').text.strip() if i.select_one('.airdrop-reward') else "TBA"
            end = i.select_one('.airdrop-end').text.replace('Ends:','').strip() if i.select_one('.airdrop-end') else "Ongoing"
            if "ongoing" in end.lower() or "active" in end.lower():
                data.append({"source": "airdrops.io", "title": title, "description": "Hot airdrop", "reward": reward, "end": end, "link": link})
    except: pass
    return data[:15]  # Max 15 total active

def scrape_news():
    """Fallback news from CoinDesk (stable)"""
    url = "https://www.coindesk.com/"
    try:
        r = requests.get(url, headers=HEADERS, timeout=15)
        soup = BeautifulSoup(r.text, 'html.parser')
        items = soup.select('.article-card, article')[:8]
        data = []
        for i in items:
            title = i.select_one('h3 a').text.strip() if i.select_one('h3 a') else ""
            link = i.select_one('a')['href'] if i.select_one('a') else ""
            if link.startswith('/'): link = "https://www.coindesk.com" + link
            date = i.select_one('.date').text.strip() if i.select_one('.date') else "Today"
            data.append({"title": title, "date": date, "link": link})
        return data
    except:
        return [{"title": "Bitcoin Update Nov 2025", "date": "Today", "link": "https://coindesk.com"}]

# Jalankan & simpan
all_airdrops = scrape_airdrops()
news_items = scrape_news()

with open("data/airdrops.json", 'w', encoding='utf-8') as f:
    json.dump(all_airdrops, f, indent=2, ensure_ascii=False)
with open("data/news.json", 'w', encoding='utf-8') as f:
    json.dump(news_items, f, indent=2, ensure_ascii=False)

print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M EET')}] Updated: {len(all_airdrops)} active airdrops | {len(news_items)} news")
